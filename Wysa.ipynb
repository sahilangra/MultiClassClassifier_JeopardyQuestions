{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required packages\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the data\n",
    "data = pd.read_csv(\"JEOPARDY_CSV.csv\")\n",
    "#making a copy of the data so to leave the original data untouched\n",
    "data_copy = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data is  (216930, 7)\n",
      "Data having value as None (3631, 7)\n",
      "New Data without 'None' in it as value (213299, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of data is \",data_copy.shape)\n",
    "\n",
    "#since all data having Round as Final Jeopardy have value None\n",
    "print(\"Data having value as None\", data_copy[data_copy[' Round'] == 'Final Jeopardy!'].shape) \n",
    "\n",
    "#we can remove those data points\n",
    "data_copy = data_copy[data_copy[' Round'] != 'Final Jeopardy!']\n",
    "print(\"New Data without 'None' in it as value\", data_copy.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of         Show Number    Air Date             Round  \\\n",
       "0              4680  2004-12-31         Jeopardy!   \n",
       "1              4680  2004-12-31         Jeopardy!   \n",
       "2              4680  2004-12-31         Jeopardy!   \n",
       "3              4680  2004-12-31         Jeopardy!   \n",
       "4              4680  2004-12-31         Jeopardy!   \n",
       "...             ...         ...               ...   \n",
       "216924         4999  2006-05-11  Double Jeopardy!   \n",
       "216925         4999  2006-05-11  Double Jeopardy!   \n",
       "216926         4999  2006-05-11  Double Jeopardy!   \n",
       "216927         4999  2006-05-11  Double Jeopardy!   \n",
       "216928         4999  2006-05-11  Double Jeopardy!   \n",
       "\n",
       "                               Category  Value  \\\n",
       "0                               HISTORY   $200   \n",
       "1       ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2           EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3                      THE COMPANY LINE   $200   \n",
       "4                   EPITAPHS & TRIBUTES   $200   \n",
       "...                                 ...    ...   \n",
       "216924                     OFF-BROADWAY  $2000   \n",
       "216925                   RIDDLE ME THIS  $2000   \n",
       "216926                        \"T\" BIRDS  $2000   \n",
       "216927           AUTHORS IN THEIR YOUTH  $2000   \n",
       "216928                       QUOTATIONS  $2000   \n",
       "\n",
       "                                                 Question        Answer  \n",
       "0       For the last 8 years of his life, Galileo was ...    Copernicus  \n",
       "1       No. 2: 1912 Olympian; football star at Carlisl...    Jim Thorpe  \n",
       "2       The city of Yuma in this state has a record av...       Arizona  \n",
       "3       In 1963, live on \"The Art Linkletter Show\", th...    McDonald's  \n",
       "4       Signer of the Dec. of Indep., framer of the Co...    John Adams  \n",
       "...                                                   ...           ...  \n",
       "216924  In 2006 the cast of this long-running hit emba...         Stomp  \n",
       "216925  This Puccini opera turns on the solution to 3 ...      Turandot  \n",
       "216926  In North America this term is properly applied...    a titmouse  \n",
       "216927  In Penny Lane, where this \"Hellraiser\" grew up...  Clive Barker  \n",
       "216928  From Ft. Sill, Okla. he made the plea, Arizona...      Geronimo  \n",
       "\n",
       "[213299 rows x 7 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()#lemmatizer\n",
    "\n",
    "ps = PorterStemmer()#stemming\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def PreprocessingText(text):\n",
    "    \"\"\"\n",
    "    input : text\n",
    "    output : preprcossed text version\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    text = text.lower() #lowercase text\n",
    "\n",
    "    text = re.sub(r\"<.*?>\",\"\", text) # removes anything enclosed between html tag <>\n",
    "\n",
    "    text = re.sub(r\"http\\S+\", \"\", text) #removes hhtp / https links\n",
    "\n",
    "    text  = text.translate(str.maketrans('', '', string.punctuation))#removes punctuation\n",
    "    text = text.lower() #lowercase text\n",
    "\n",
    "    word_tokens = word_tokenize(text)#tokenize words\n",
    "    filtered_sentence = [lemmatizer.lemmatize(ps.stem(w)) for w in word_tokens if not w in stop_words]#stem the text, followed by lemmatization\n",
    "\n",
    "    return \" \".join(filtered_sentence)#concatenates list to string\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[' Question'] = data_copy[' Question'].apply(PreprocessingText)#apply preprocessing over Question columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge columns Round, Category, Question into a new columns called concatenate\n",
    "data_copy['concatenate'] = data_copy[' Round'] + \" \" + data_copy[' Category'] + \" \" + data_copy[' Question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>concatenate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>last 8 year life galileo hous arrest espous ma...</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>Jeopardy! HISTORY last 8 year life galileo hou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>2 1912 olympian footbal star carlisl indian sc...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>Jeopardy! ESPN's TOP 10 ALL-TIME ATHLETES 2 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>citi yuma state record averag 4055 hour sunshi...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Jeopardy! EVERYBODY TALKS ABOUT IT... citi yum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>1963 live art linklett show compani serv billi...</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>Jeopardy! THE COMPANY LINE 1963 live art linkl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>signer dec indep framer constitut mass second ...</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>Jeopardy! EPITAPHS &amp; TRIBUTES signer dec indep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216924</th>\n",
       "      <td>4999</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>OFF-BROADWAY</td>\n",
       "      <td>$2000</td>\n",
       "      <td>2006 cast longrun hit embark exuber noisi camp...</td>\n",
       "      <td>Stomp</td>\n",
       "      <td>Double Jeopardy! OFF-BROADWAY 2006 cast longru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216925</th>\n",
       "      <td>4999</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>RIDDLE ME THIS</td>\n",
       "      <td>$2000</td>\n",
       "      <td>puccini opera turn solut 3 riddl pose heroin</td>\n",
       "      <td>Turandot</td>\n",
       "      <td>Double Jeopardy! RIDDLE ME THIS puccini opera ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216926</th>\n",
       "      <td>4999</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>\"T\" BIRDS</td>\n",
       "      <td>$2000</td>\n",
       "      <td>north america term properli appli 4 speci cres...</td>\n",
       "      <td>a titmouse</td>\n",
       "      <td>Double Jeopardy! \"T\" BIRDS north america term ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216927</th>\n",
       "      <td>4999</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>AUTHORS IN THEIR YOUTH</td>\n",
       "      <td>$2000</td>\n",
       "      <td>penni lane hellrais grew barber shave anoth cu...</td>\n",
       "      <td>Clive Barker</td>\n",
       "      <td>Double Jeopardy! AUTHORS IN THEIR YOUTH penni ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216928</th>\n",
       "      <td>4999</td>\n",
       "      <td>2006-05-11</td>\n",
       "      <td>Double Jeopardy!</td>\n",
       "      <td>QUOTATIONS</td>\n",
       "      <td>$2000</td>\n",
       "      <td>ft sill okla made plea arizona land home fathe...</td>\n",
       "      <td>Geronimo</td>\n",
       "      <td>Double Jeopardy! QUOTATIONS ft sill okla made ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213299 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Show Number    Air Date             Round  \\\n",
       "0              4680  2004-12-31         Jeopardy!   \n",
       "1              4680  2004-12-31         Jeopardy!   \n",
       "2              4680  2004-12-31         Jeopardy!   \n",
       "3              4680  2004-12-31         Jeopardy!   \n",
       "4              4680  2004-12-31         Jeopardy!   \n",
       "...             ...         ...               ...   \n",
       "216924         4999  2006-05-11  Double Jeopardy!   \n",
       "216925         4999  2006-05-11  Double Jeopardy!   \n",
       "216926         4999  2006-05-11  Double Jeopardy!   \n",
       "216927         4999  2006-05-11  Double Jeopardy!   \n",
       "216928         4999  2006-05-11  Double Jeopardy!   \n",
       "\n",
       "                               Category  Value  \\\n",
       "0                               HISTORY   $200   \n",
       "1       ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2           EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3                      THE COMPANY LINE   $200   \n",
       "4                   EPITAPHS & TRIBUTES   $200   \n",
       "...                                 ...    ...   \n",
       "216924                     OFF-BROADWAY  $2000   \n",
       "216925                   RIDDLE ME THIS  $2000   \n",
       "216926                        \"T\" BIRDS  $2000   \n",
       "216927           AUTHORS IN THEIR YOUTH  $2000   \n",
       "216928                       QUOTATIONS  $2000   \n",
       "\n",
       "                                                 Question        Answer  \\\n",
       "0       last 8 year life galileo hous arrest espous ma...    Copernicus   \n",
       "1       2 1912 olympian footbal star carlisl indian sc...    Jim Thorpe   \n",
       "2       citi yuma state record averag 4055 hour sunshi...       Arizona   \n",
       "3       1963 live art linklett show compani serv billi...    McDonald's   \n",
       "4       signer dec indep framer constitut mass second ...    John Adams   \n",
       "...                                                   ...           ...   \n",
       "216924  2006 cast longrun hit embark exuber noisi camp...         Stomp   \n",
       "216925       puccini opera turn solut 3 riddl pose heroin      Turandot   \n",
       "216926  north america term properli appli 4 speci cres...    a titmouse   \n",
       "216927  penni lane hellrais grew barber shave anoth cu...  Clive Barker   \n",
       "216928  ft sill okla made plea arizona land home fathe...      Geronimo   \n",
       "\n",
       "                                              concatenate  \n",
       "0       Jeopardy! HISTORY last 8 year life galileo hou...  \n",
       "1       Jeopardy! ESPN's TOP 10 ALL-TIME ATHLETES 2 19...  \n",
       "2       Jeopardy! EVERYBODY TALKS ABOUT IT... citi yum...  \n",
       "3       Jeopardy! THE COMPANY LINE 1963 live art linkl...  \n",
       "4       Jeopardy! EPITAPHS & TRIBUTES signer dec indep...  \n",
       "...                                                   ...  \n",
       "216924  Double Jeopardy! OFF-BROADWAY 2006 cast longru...  \n",
       "216925  Double Jeopardy! RIDDLE ME THIS puccini opera ...  \n",
       "216926  Double Jeopardy! \"T\" BIRDS north america term ...  \n",
       "216927  Double Jeopardy! AUTHORS IN THEIR YOUTH penni ...  \n",
       "216928  Double Jeopardy! QUOTATIONS ft sill okla made ...  \n",
       "\n",
       "[213299 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using TfidfVectorizer to turn the string into a set of integers\n",
    "#Alternatively Count Vectorizer can also be used.\n",
    "#I went with TFIDF cause the stop words have already been removed, and tfidf can perform better\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(data_copy['concatenate'])#fit tfidf on the entire column\n",
    "Y = data_copy[' Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)#splitting into train-test with 25 % as testsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape  (159974, 86572)\n",
      "Testing shape  (53325, 86572)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training shape \",X_train.shape)\n",
    "print(\"Testing shape \",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use default model\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "Prediction = model.predict(X_test)\n",
    "acc_score = model.score(X_test, y_test)\n",
    "c_matrix = confusion_matrix(y_test, Prediction)\n",
    "\n",
    "precision, recall, f1_score, support = precision_recall_fscore_support(y_test, Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score 0.13819034224097515\n",
      "Model confusion matrix [[7 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Model precision [0.05185185 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.09896433 0.10164384 0.         0.         0.08569016\n",
      " 0.         0.06807728 0.01149425 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.17152822 0.0985342  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.09025507 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.17784722 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.11665732\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.08432371 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.13864275\n",
      " 0.         0.         0.         0.        ]\n",
      "Model recall [0.01335878 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.07641048 0.07674803 0.         0.         0.0719603\n",
      " 0.         0.05576488 0.00251889 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.2114658  0.08530137 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.06233062 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.2522633  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.09433107\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.05887001 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.16130249\n",
      " 0.         0.         0.         0.        ]\n",
      "Model f1_score  [0.02124431 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.08623715 0.08745875 0.         0.         0.07822736\n",
      " 0.         0.06130903 0.00413223 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.18941472 0.09144153 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.07373764 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.20861766 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.10431294\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.06933457 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.14911669\n",
      " 0.         0.         0.         0.        ]\n",
      "Model support [  524    10     0     1   112     1     2    24    46     1   146     0\n",
      "    65     9    41     1     7     2     2  2251  4834     1     1  2821\n",
      "     1  2654   397     1     5    38     6     0    27    68    21     6\n",
      "    12     1     1  7675  2837   205     2    12     2     1    13    14\n",
      "     9     1    10  2214    91     1     1     9     1     4     4     2\n",
      "     8 10604     3    66     1     1     7     4     2     3     2  2205\n",
      "    20     1     2     1     6     1     0  5062     9     2     1     3\n",
      "    65     5     1     1     1  7954     2     1    32     1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model score\", acc_score)\n",
    "print(\"Model confusion matrix\", c_matrix)\n",
    "print(\"Model precision\", precision)\n",
    "print(\"Model recall\", recall)\n",
    "print(\"Model f1_score \", f1_score)\n",
    "print(\"Model support\", support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to deploy model via flask server\n",
    "from flask import Flask\n",
    "from flask import request\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/QuestionWorth', methods=['POST'])\n",
    "def question():\n",
    "    if request.method == 'POST':\n",
    "        #get the required element off JSON \n",
    "        question = request.args.get('question', default=0, type=int)\n",
    "        Round = request.args.get('Round', default=0, type=int)\n",
    "        Category = request.args.get('Category', default=0, type=int)\n",
    "    \n",
    "        #preprocess\n",
    "        question = PreprocessingText(question)\n",
    "        \n",
    "        #concatenate\n",
    "        concatenate = Round + \" \" + Category + \" \" + question\n",
    "        \n",
    "        #predict\n",
    "        return (\"Value for the question is\",model.predict(concatenate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Use pretrained model ELMo with tensorflow hub\"\"\"\n",
    "\n",
    "path = r\"C:\\Users\\s\\Desktop\\Wysa\\elmo_3\"\n",
    "Module = hub.load(path)\n",
    "def encoderElmo(words, batch_size = 1000):\n",
    "    \n",
    "    ElmoEncoded = []\n",
    "    start_batch_size = 0# starts from 0\n",
    "    \n",
    "    for i in range(len(words) % batch_size ):\n",
    "        end_batch_size = start_batch_size + batch_size #1000 is batch size, so 1000 textsgo to elmo each time\n",
    "        \n",
    "        temp = words[start_batch_size : end_batch_size]\n",
    "        \n",
    "        ElmoEncoded.append(Module(np.array(temp)))#each run 1000 gets admitted to elmoencoded list\n",
    "        \n",
    "        start_batch_size += 1000\n",
    "        \n",
    "    return ElmoEncoded\n",
    "        \n",
    "\n",
    "data_copy['concatenate'] = encoderElmo(data_copy['concatenate'])#send the questions in\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(1024, activation=\"relu\", name=\"layer1\"),#1024 is the output dimension for ELMO\n",
    "        layers.Dense(512, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(150, activation=\"softmax\", name=\"layer3\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_copy['concatenate'], Y, test_size=0.25)#split the data\n",
    "\n",
    "model.fit(X_train, X_test)\n",
    "\n",
    "Prediction = model.predict(X_test)\n",
    "acc_score = model.score(X_test, y_test)\n",
    "c_matrix = confusion_matrix(y_test, Prediction)\n",
    "\n",
    "precision, recall, f1_score, support = precision_recall_fscore_support(y_test, Prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
